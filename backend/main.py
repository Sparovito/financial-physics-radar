import uvicorn
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse
from pydantic import BaseModel
from typing import Optional, List
import numpy as np
import pandas as pd
import os
import sys

# Ensure the directory containing this file is in the Python path
# This fixes "ModuleNotFoundError: No module named 'logic'" on Railway
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from logic import MarketData, ActionPath, FourierEngine, MarketScanner

app = FastAPI(title="Financial Physics API")

# Abilita CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Modelli Dati (Pydantic)
class AnalysisRequest(BaseModel):
    ticker: str
    alpha: float = 200.0
    beta: float = 1.0
    top_k: int = 5
    forecast_days: int = 60
    start_date: Optional[str] = "2023-01-01"
    end_date: Optional[str] = None  # If set, truncate data to this date (simulate past)
    use_cache: bool = False # If True, try to use cached full history

# Global Cache for Full Ticker History (DataFrame)
# Key: Ticker, Value: Pandas Series (Full History)
TICKER_CACHE = {}

class ScanRequest(BaseModel):
    tickers: List[str]

@app.post("/scan")
async def scan_market(req: ScanRequest):
    try:
        print(f"ðŸ“¡ Radar Scan richiesto per {len(req.tickers)} titoli...")
        scanner = MarketScanner(req.tickers)
        results = scanner.scan()
        return {"status": "ok", "results": results}
    except Exception as e:
        print(f"Errore scan: {e}")
        return {"status": "error", "detail": str(e)}

@app.post("/analyze")
async def analyze_stock(req: AnalysisRequest):
    try:
        print(f"Ricevuta richiesta: {req.dict()}")
        
        # 1. Scarica Dati & Gestione Cache Avanzata
        px = None
        full_frozen_data = None
        
        # Check Cache
        use_cache_data = False
        if req.use_cache and req.ticker in TICKER_CACHE:
            cached_obj = TICKER_CACHE[req.ticker]
            cached_px = cached_obj["px"]
            
            # Verify Date Coverage
            if req.start_date:
                req_start_ts = pd.Timestamp(req.start_date)
                # If cached data starts significantly later than requested, it's insufficient
                if cached_px.index[0] > req_start_ts + pd.Timedelta(days=10):
                    print(f"âš ï¸ Cache miss (Storia insufficiente): Cached({cached_px.index[0].date()}) > Req({req.start_date})")
                    use_cache_data = False
                else:
                    use_cache_data = True
            else:
                use_cache_data = True

        if use_cache_data:
            print(f"âš¡ CACHE HIT: Uso dati in memoria per {req.ticker}")
            cached_obj = TICKER_CACHE[req.ticker]
            px = cached_obj["px"]
            full_frozen_data = cached_obj.get("frozen", None)
            # Load ZigZag Series
            zigzag_series = cached_obj.get("zigzag", None)
        else:
            # Scarica storia COMPLETA
            print(f"ðŸŒ API FETCH: Scarico dati freschi per {req.ticker}...")
            md = MarketData(req.ticker, start_date=req.start_date, end_date=None)
            px = md.fetch()

            # [NEW] Calculate Cumulative Direction (ZigZag) - HOURLY AGGREGATED
            try:
                # Fetch hourly data for more granular ZigZag
                print(f"ðŸ“Š Fetching hourly data for ZigZag...")
                hourly_data = md.ticker_obj.history(period="2y", interval="1h")
                
                if not hourly_data.empty and 'Open' in hourly_data.columns and 'Close' in hourly_data.columns:
                    # Calculate hourly direction (+1, -1, 0)
                    hourly_diff = hourly_data['Close'] - hourly_data['Open']
                    hourly_signs = hourly_diff.apply(lambda x: 1 if x > 0 else -1 if x < 0 else 0)
                    
                    # Group by date and sum all hourly directions
                    hourly_signs.index = pd.to_datetime(hourly_signs.index).date
                    daily_net = hourly_signs.groupby(hourly_signs.index).sum()
                    
                    # Align with px dates and cumsum
                    zigzag_values = []
                    cumsum = 0
                    for date in px.index:
                        date_key = date.date()
                        if date_key in daily_net.index:
                            cumsum += daily_net[date_key]
                        zigzag_values.append(cumsum)
                    
                    zigzag_series = pd.Series(zigzag_values, index=px.index)
                    print(f"âœ… ZigZag calcolato su {len(hourly_data)} candele orarie")
                else:
                    # Fallback to daily if hourly not available
                    print("âš ï¸ Hourly data not available, using daily fallback")
                    d_open = md.df_full['Open']
                    d_close = md.df_full['Close']
                    diff = d_close - d_open
                    signs = diff.apply(lambda x: 1 if x > 0 else -1 if x < 0 else 0)
                    zigzag_series = signs.cumsum()
            except Exception as e:
                print(f"âš ï¸ Errore calcolo ZigZag: {e}")
                zigzag_series = pd.Series([0]*len(px), index=px.index)
            
            # --- PRE-CALCOLO FROZEN HISTORY (Heavy Computation) ---
            print(f"ðŸ§Š Pre-calcolo Frozen History completa (puÃ² richiedere tempo)...")
            SAMPLE_EVERY = 1
            MIN_POINTS = 100
            
            f_kin, f_pot, f_dates = [], [], []
            n_total = len(px)
            
            for t in range(MIN_POINTS, n_total, SAMPLE_EVERY):
                px_t = px.iloc[:t+1]
                try:
                    mech_t = ActionPath(px_t, alpha=req.alpha, beta=req.beta)
                    # Save RAW DENSITY
                    # [MOD] Kinetics at T-24 days (Shifted) as requested
                    lag_idx = -25 # -1 is Today, so -25 is 24 days ago
                    if len(mech_t.kin_density) >= 25:
                        f_kin.append(round(float(mech_t.kin_density.iloc[lag_idx]), 2))
                    else:
                        f_kin.append(0.0)
                    f_pot.append(round(float(mech_t.pot_density.iloc[-1]), 2))
                    f_dates.append(px.index[t].strftime('%Y-%m-%d'))
                except:
                    continue
            
            full_frozen_data = {
                "dates": f_dates,
                "kin": f_kin,
                "pot": f_pot
            }
            
            # Salva tutto in cache
            TICKER_CACHE[req.ticker] = {
                "px": px,
                "frozen": full_frozen_data,
                "zigzag": zigzag_series
            }

        # --- SIMULATION TIME TRAVEL (Slicing istantaneo) ---
        if req.end_date:
            end_ts = pd.Timestamp(req.end_date)
            # Slice Prices
            px = px[px.index <= end_ts]
            
            # Slice Frozen Data
            # Troviamo l'indice fin dove arrivare nei dati frozen
            target_date_str = req.end_date
            
            # Slice ZigZag (Series)
            if zigzag_series is not None:
                zigzag_series = zigzag_series[zigzag_series.index <= end_ts]
            
            # Filtro rapido liste (date frozen sono giÃ  sorted)
            trunc_dates = []
            trunc_kin = []
            trunc_pot = []
            
            # Ottimizzazione: bisect o semplice loop finchÃ© <= date
            # Dato che sono stringhe YYYY-MM-DD, confronto lessicografico funziona
            for i, d in enumerate(full_frozen_data["dates"]):
                if d <= target_date_str:
                    trunc_dates.append(d)
                    trunc_kin.append(full_frozen_data["kin"][i])
                    trunc_pot.append(full_frozen_data["pot"][i])
                else:
                    break # Stop appena superiamo la data
            
            frozen_dates = trunc_dates
            frozen_z_kin = trunc_kin
            frozen_z_pot = trunc_pot
            
            print(f"ðŸ• Simulating past: data truncated to {req.end_date}")
        else:
            # Dati completi
            frozen_dates = full_frozen_data["dates"]
            frozen_z_kin = full_frozen_data["kin"]
            frozen_z_pot = full_frozen_data["pot"]
        
        # Prepare ZigZag List
        zigzag_line = zigzag_series.values.tolist() if zigzag_series is not None else []
        
        # 2. Calcola Minima Azione (Live su dati tranciati)
        mechanics = ActionPath(px, alpha=req.alpha, beta=req.beta)
        
        # 3. Calcola Fourier
        fourier = FourierEngine(px, top_k=req.top_k)
        future_idx, future_vals = fourier.reconstruct_scenario(future_horizon=req.forecast_days)
        
        # 4. Prepara Risposta JSON
        dates_historical = px.index.strftime('%Y-%m-%d').tolist()
        
        # Prezzi
        price_real = px.values.tolist()
        price_min_action = mechanics.px_star.values.tolist()
        fundamentals = mechanics.F.values.tolist()
        
        # DensitÃ  Energia
        kin_density = mechanics.kin_density.values.tolist()
        pot_density = mechanics.pot_density.values.tolist()
        cum_action = mechanics.cumulative_action.values.tolist()
        
        # Indicatori Tecnici
        slope_line = mechanics.dX.values.tolist()
        z_residuo_line = mechanics.z_residuo.values.tolist()
        
        # ROC (Rate of Change)
        ROC_PERIOD = 20
        roc = ((px - px.shift(ROC_PERIOD)) / px.shift(ROC_PERIOD) * 100).fillna(0)
        roc_line = roc.values.tolist()
        
        # Z-Score del ROC
        roll_roc_mean = roc.rolling(window=252, min_periods=20).mean()
        roll_roc_std = roc.rolling(window=252, min_periods=20).std()
        z_roc = ((roc - roll_roc_mean) / (roll_roc_std + 1e-6)).fillna(0)
        z_roc_line = z_roc.values.tolist()
        
        # 5. Backtest Strategy
        # Calculate ROLLING Z-Scores to avoid look-ahead bias (252-day window)
        ZSCORE_WINDOW = 252
        
        kin = mechanics.kin_density
        roll_kin_mean = kin.rolling(window=ZSCORE_WINDOW, min_periods=20).mean()
        roll_kin_std = kin.rolling(window=ZSCORE_WINDOW, min_periods=20).std()
        z_kin_series = ((kin - roll_kin_mean) / (roll_kin_std + 1e-6)).fillna(0).values.tolist()
        
        slope = mechanics.dX
        roll_slope_mean = slope.rolling(window=ZSCORE_WINDOW, min_periods=20).mean()
        roll_slope_std = slope.rolling(window=ZSCORE_WINDOW, min_periods=20).std()
        z_slope_series = ((slope - roll_slope_mean) / (roll_slope_std + 1e-6)).fillna(0).values.tolist()
        
        from logic import backtest_strategy
        
        # --- STRATEGIA 1: LIVE KINETIC (Originale) ---
        backtest_result = backtest_strategy(
            prices=price_real,
            z_kinetic=z_kin_series,
            z_slope=z_slope_series,
            dates=dates_historical,
            start_date=req.start_date,
            end_date=req.end_date
        )
        
        # --- STRATEGIA 2: FROZEN POTENTIAL (Richiesta User) ---
        # 1. Calcoliamo Z-Score della serie Frozen Potential (che Ã¨ Raw Density)
        #    La serie frozen Ã¨ piÃ¹ corta (parte da MIN_POINTS). Dobbiamo allinearla a Price.
        
        # Calculate padding size (difference in length)
        padding_size = len(price_real) - len(frozen_z_pot)
        
        # Prepend zeros/NaNs to align time series
        # Using 0 as neutral value for Z-score calc is safer than NaN for backtest logic
        aligned_frozen_pot = [0] * padding_size + frozen_z_pot
        
        # Ora Ã¨ allineato
        frozen_pot_series = pd.Series(aligned_frozen_pot).fillna(0)
        
        # Calculate rolling stats
        roll_fpot_mean = frozen_pot_series.rolling(window=ZSCORE_WINDOW, min_periods=20).mean()
        roll_fpot_std = frozen_pot_series.rolling(window=ZSCORE_WINDOW, min_periods=20).std()
        
        # Questo Ã¨ lo Z-Score del Potenziale Frozen Point-in-Time
        z_frozen_pot_score = ((frozen_pot_series - roll_fpot_mean) / (roll_fpot_std + 1e-6)).fillna(0).values.tolist()
        
        # 2. Eseguiamo backtest sostituendo Kinetic con Frozen Potential
        #    Nota: Usiamo ancora z_slope Live per la direzione (Long/Short)
        backtest_result_frozen = backtest_strategy(
            prices=price_real,
            z_kinetic=z_frozen_pot_score, # Sostituiamo segnale trigger
            z_slope=z_slope_series,       # Manteniamo filtro direzionale
            dates=dates_historical,
            start_date=req.start_date,
            end_date=req.end_date
        )
        
        # Dati Futuri (Proiezione)
        # Nota: future_idx potrebbe contenere timestamp o interi, convertiamo
        try:
            dates_future = [d.strftime('%Y-%m-%d') for d in future_idx]
        except:
            # Fallback se non sono date
            dates_future = [str(d) for d in future_idx]
            
        future_scenario = future_vals.tolist()
        
        # Componenti Fourier
        fourier_comps = fourier.get_components()
        
        # [NEW] Market Metrics
        # 1. Avg Abs Kinetic
        avg_abs_kin = ((kin - roll_kin_mean) / (roll_kin_std + 1e-6)).fillna(0).abs().mean()
        
        # 2. Market Cap (Based on Diagnostic: fast_info.market_cap can be None for ETFs/Crypto)
        mkt_cap = None
        
        # A. Try FastInfo (works for stocks like AAPL, NVDA)
        try:
            mkt_cap = md.ticker_obj.fast_info.market_cap
        except:
            pass
        
        # B. Fallback to Slow Info (works for ETFs like SPY, Crypto like BTC-USD)
        if mkt_cap is None:
            try:
                info = md.ticker_obj.info
                mkt_cap = info.get('marketCap') or info.get('totalAssets')
            except:
                pass
        
        # C. Final Fallback: Calc from shares * price (for futures like GC=F)
        if mkt_cap is None:
            try:
                shares = md.ticker_obj.fast_info.shares
                price = md.ticker_obj.fast_info.last_price
                if shares and price:
                    mkt_cap = shares * price
            except:
                pass
        
        # Ensure numeric or 0
        if mkt_cap is None:
            mkt_cap = 0
        
        # DEBUG LOG
        print(f"ðŸ“Š {req.ticker} Market Cap = {mkt_cap}")
        
        return {
            "status": "ok",
            "ticker": req.ticker,
            "avg_abs_kin": round(float(avg_abs_kin), 2),
            "market_cap": mkt_cap,
            "dates": dates_historical,
            "prices": price_real,
            "volume": md.df_full['Volume'].fillna(0).tolist() if hasattr(md, 'df_full') and 'Volume' in md.df_full.columns else [0]*len(price_real),
            "min_action": price_min_action,
            "fundamentals": fundamentals,
            "energy": {
                "kinetic": kin_density,
                "potential": pot_density,
                "cumulative": cum_action,
                "z_kinetic": z_kin_series,
                "z_slope": z_slope_series
            },
            "indicators": {
                "slope": slope_line,
                "z_residuo": z_residuo_line,
                "roc": roc_line,
                "z_roc": z_roc_line,
                "zigzag": zigzag_line   # [NEW] Cumulative Direction
            },
            "backtest": backtest_result,                  # Strategia Live
            "frozen_strategy": backtest_result_frozen,    # Strategia Frozen (NEW)
            "forecast": {
                "dates": dates_future,
                "values": future_scenario
            },
            "fourier_components": fourier_comps,
            "frozen": {
                "dates": frozen_dates,
                "z_kinetic": frozen_z_kin,
                "z_potential": frozen_z_pot
            }
        }

    except Exception as e:
        import traceback
        tb = traceback.format_exc()
        print(f"Errore server: {tb}")
        raise HTTPException(status_code=500, detail=f"Errore Interno: {str(e)}\n\n{tb}")

@app.get("/health")
def health_check():
    return {"status": "running"}

# --- STATIC FILES SERVING (Fallback) ---

# Construct absolute path to frontend directory to avoid CWD issues
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
FRONTEND_DIR = os.path.join(BASE_DIR, "..", "frontend")

# 1. Mount Static Files (JS/CSS)
app.mount("/static", StaticFiles(directory=FRONTEND_DIR), name="static")

# 2. Serve Index at Root
@app.get("/")
async def read_index():
    return FileResponse(os.path.join(FRONTEND_DIR, 'index.html'))

# 3. Serve other files from frontend root (app.js, style.css)
# MUST BE LAST to avoid shadowing API routes
@app.get("/{filename}")
async def serve_frontend_file(filename: str):
    file_path = os.path.join(FRONTEND_DIR, filename)
    if os.path.exists(file_path) and os.path.isfile(file_path):
        return FileResponse(file_path)
    raise HTTPException(status_code=404, detail="File not found")


if __name__ == "__main__":
    uvicorn.run(app, host="127.0.0.1", port=8000)
